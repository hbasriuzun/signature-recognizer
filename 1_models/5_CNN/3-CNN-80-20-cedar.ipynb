{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2673, Accuracy: 0.9379\n",
      "\n",
      "Epoch [2/5], Loss: 0.0000, Accuracy: 1.0000\n",
      "\n",
      "Epoch [3/5], Loss: 0.0000, Accuracy: 1.0000\n",
      "\n",
      "Epoch [4/5], Loss: 0.0000, Accuracy: 1.0000\n",
      "\n",
      "Epoch [5/5], Loss: 0.0000, Accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Modeli eğit ve test et\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_model(model, train_loader, criterion, optimizer, num_epochs)\n\u001b[0;32m----> 3\u001b[0m test_model(model, \u001b[43mtest_loader\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Modeli eğit ve test et\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:43:35.991794Z",
     "iopub.status.busy": "2024-12-01T11:43:35.991138Z",
     "iopub.status.idle": "2024-12-01T11:43:40.376795Z",
     "shell.execute_reply": "2024-12-01T11:43:40.375927Z",
     "shell.execute_reply.started": "2024-12-01T11:43:35.991760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset,random_split\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:58:29.160612Z",
     "iopub.status.busy": "2024-12-01T11:58:29.160261Z",
     "iopub.status.idle": "2024-12-01T11:58:29.164877Z",
     "shell.execute_reply": "2024-12-01T11:58:29.164038Z",
     "shell.execute_reply.started": "2024-12-01T11:58:29.160581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "test_split_ratio = 0.2  # Verinin yüzde 20'sini test seti olarak ayır\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:43:40.386113Z",
     "iopub.status.busy": "2024-12-01T11:43:40.385737Z",
     "iopub.status.idle": "2024-12-01T11:43:40.396239Z",
     "shell.execute_reply": "2024-12-01T11:43:40.395344Z",
     "shell.execute_reply.started": "2024-12-01T11:43:40.386064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Özel Dataset sınıfı oluşturma\n",
    "class SignatureDataset(Dataset):\n",
    "    def __init__(self, real_dir, forg_dir, transform=None):\n",
    "        self.real_dir = real_dir\n",
    "        self.forg_dir = forg_dir\n",
    "        self.transform = transform\n",
    "        # Yalnızca resim dosyalarını ekle (Thumbs.db gibi dosyaları atlar)\n",
    "        self.real_images = [img for img in os.listdir(real_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        self.forg_images = [img for img in os.listdir(forg_dir) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.real_images) + len(self.forg_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.real_images):\n",
    "            img_path = os.path.join(self.real_dir, self.real_images[idx])\n",
    "            label = 0  # Orijinal imza\n",
    "        else:\n",
    "            img_path = os.path.join(self.forg_dir, self.forg_images[idx - len(self.real_images)])\n",
    "            label = 1  # Sahte imza\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except (UnidentifiedImageError, FileNotFoundError):\n",
    "            # Hatalı dosyaları atlamak için None döndür\n",
    "            return None\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:43:40.398235Z",
     "iopub.status.busy": "2024-12-01T11:43:40.397920Z",
     "iopub.status.idle": "2024-12-01T11:43:40.468384Z",
     "shell.execute_reply": "2024-12-01T11:43:40.467461Z",
     "shell.execute_reply.started": "2024-12-01T11:43:40.398192Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Veri dönüşümleri\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset oluşturma\n",
    "full_dataset = SignatureDataset(\n",
    "    real_dir=\"/Users/hbuzun/Documents/GitHub/Signature_recegnator/1_models/1_veri_setleri/1_Cedar_dataset/full_org\",\n",
    "    forg_dir=\"/Users/hbuzun/Documents/GitHub/Signature_recegnator/1_models/1_veri_setleri/1_Cedar_dataset/full_forg\",\n",
    "    transform=data_transforms\n",
    ")\n",
    "\n",
    "# Dataset'leri eğitim ve test setlerine ayırma\n",
    "test_size = int(len(full_dataset) * test_split_ratio)\n",
    "train_size = len(full_dataset) - test_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader oluşturma\n",
    "def collate_fn(batch):\n",
    "    # None değerlerini atla\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    return torch.utils.data.default_collate(batch)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:43:40.470084Z",
     "iopub.status.busy": "2024-12-01T11:43:40.469675Z",
     "iopub.status.idle": "2024-12-01T11:43:45.219095Z",
     "shell.execute_reply": "2024-12-01T11:43:45.218091Z",
     "shell.execute_reply.started": "2024-12-01T11:43:40.470041Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/hbuzun/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "7.7%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Modeli yükleme\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvgg16\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m6\u001b[39m]\u001b[38;5;241m.\u001b[39min_features, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torchvision/models/_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs\u001b[38;5;241m.\u001b[39mkeys()),\u001b[38;5;250m \u001b[39mseparate_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as positional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torchvision/models/_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[1;32m    226\u001b[0m     kwargs[weights_param] \u001b[38;5;241m=\u001b[39m default_weights_arg\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torchvision/models/vgg.py:433\u001b[0m, in \u001b[0;36mvgg16\u001b[0;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"VGG-16 from `Very Deep Convolutional Networks for Large-Scale Image Recognition <https://arxiv.org/abs/1409.1556>`__.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;124;03m    :members:\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    431\u001b[0m weights \u001b[38;5;241m=\u001b[39m VGG16_Weights\u001b[38;5;241m.\u001b[39mverify(weights)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vgg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torchvision/models/vgg.py:105\u001b[0m, in \u001b[0;36m_vgg\u001b[0;34m(cfg, batch_norm, weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m model \u001b[38;5;241m=\u001b[39m VGG(make_layers(cfgs[cfg], batch_norm\u001b[38;5;241m=\u001b[39mbatch_norm), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torchvision/models/_api.py:90\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torch/hub.py:867\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    865\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/site-packages/torch/hub.py:744\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[1;32m    737\u001b[0m     total\u001b[38;5;241m=\u001b[39mfile_size,\n\u001b[1;32m    738\u001b[0m     disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m progress,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    741\u001b[0m     unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m    742\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m         buffer \u001b[38;5;241m=\u001b[39m \u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREAD_DATA_CHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    746\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/3-9-13_NN/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Modeli yükleme\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss ve optimizer tanımlama\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:43:45.220564Z",
     "iopub.status.busy": "2024-12-01T11:43:45.220288Z",
     "iopub.status.idle": "2024-12-01T11:43:45.228989Z",
     "shell.execute_reply": "2024-12-01T11:43:45.228200Z",
     "shell.execute_reply.started": "2024-12-01T11:43:45.220539Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Eğitim fonksiyonu\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            # None döndüren dosyaları atla\n",
    "            if images is None or labels is None:\n",
    "                continue\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Test fonksiyonu\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T11:58:37.186993Z",
     "iopub.status.busy": "2024-12-01T11:58:37.186654Z",
     "iopub.status.idle": "2024-12-01T12:05:01.898615Z",
     "shell.execute_reply": "2024-12-01T12:05:01.897743Z",
     "shell.execute_reply.started": "2024-12-01T11:58:37.186963Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=50176, out_features=128, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/30], Loss: 0.9881, Accuracy: 0.5232\n",
      "Epoch [2/30], Loss: 0.6040, Accuracy: 0.6856\n",
      "Epoch [3/30], Loss: 0.5233, Accuracy: 0.7491\n",
      "Epoch [4/30], Loss: 0.3885, Accuracy: 0.8291\n",
      "Epoch [5/30], Loss: 0.2810, Accuracy: 0.8793\n",
      "Epoch [6/30], Loss: 0.2404, Accuracy: 0.9029\n",
      "Epoch [7/30], Loss: 0.2174, Accuracy: 0.9072\n",
      "Epoch [8/30], Loss: 0.1854, Accuracy: 0.9309\n",
      "Epoch [9/30], Loss: 0.1211, Accuracy: 0.9583\n",
      "Epoch [10/30], Loss: 0.0638, Accuracy: 0.9801\n",
      "Epoch [11/30], Loss: 0.0228, Accuracy: 0.9943\n",
      "Epoch [12/30], Loss: 0.0107, Accuracy: 0.9976\n",
      "Epoch [13/30], Loss: 1.1609, Accuracy: 0.6752\n",
      "Epoch [14/30], Loss: 0.4644, Accuracy: 0.7131\n",
      "Epoch [15/30], Loss: 0.3443, Accuracy: 0.8059\n",
      "Epoch [16/30], Loss: 0.2431, Accuracy: 0.8958\n",
      "Epoch [17/30], Loss: 0.2238, Accuracy: 0.9100\n",
      "Epoch [18/30], Loss: 0.1126, Accuracy: 0.9583\n",
      "Epoch [19/30], Loss: 0.0897, Accuracy: 0.9621\n",
      "Epoch [20/30], Loss: 0.0484, Accuracy: 0.9820\n",
      "Epoch [21/30], Loss: 0.3352, Accuracy: 0.8589\n",
      "Epoch [22/30], Loss: 0.1177, Accuracy: 0.9517\n",
      "Epoch [23/30], Loss: 0.1115, Accuracy: 0.9593\n",
      "Epoch [24/30], Loss: 0.0584, Accuracy: 0.9763\n",
      "Epoch [25/30], Loss: 0.0358, Accuracy: 0.9891\n",
      "Epoch [26/30], Loss: 0.0279, Accuracy: 0.9929\n",
      "Epoch [27/30], Loss: 0.0151, Accuracy: 0.9981\n",
      "Epoch [28/30], Loss: 0.0114, Accuracy: 0.9981\n",
      "Epoch [29/30], Loss: 0.1127, Accuracy: 0.9612\n",
      "Epoch [30/30], Loss: 0.0390, Accuracy: 0.9910\n",
      "Test Loss: 0.1256, Test Accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Daha basit bir CNN modeli\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Özellik çıkarma katmanları\n",
    "        self.features = nn.Sequential(\n",
    "            # Blok 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Daha az filtre\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Özellik haritası boyutunu azaltır\n",
    "            \n",
    "            # Blok 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Blok 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Sınıflandırıcı katmanları\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 256),  # Daha az nöron\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, num_classes)  # Çıkış sınıf sayısı\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # Özellik çıkarımı\n",
    "        x = torch.flatten(x, 1)  # Düzleştirme (flatten)\n",
    "        x = self.classifier(x)  # Sınıflandırıcı\n",
    "        return x\n",
    "\n",
    "# Modeli tanımlama\n",
    "model = SimpleCNN(num_classes=2)  # 2 sınıf (örneğin, imza tanımlama)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss fonksiyonu ve optimizer tanımlama\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Model özet bilgisi (isteğe bağlı)\n",
    "print(model)\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "test_model(model, test_loader, criterion)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T12:17:14.755340Z",
     "iopub.status.busy": "2024-12-01T12:17:14.754969Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DisplacementFeatureCNN(\n",
      "  (features): ModuleList(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Epoch [1/30], Loss: 2602.3014, Accuracy: 0.4915\n",
      "Epoch [2/30], Loss: 2312.6819, Accuracy: 0.5123\n",
      "Epoch [3/30], Loss: 1551.1903, Accuracy: 0.5450\n",
      "Epoch [4/30], Loss: 1531.7122, Accuracy: 0.5421\n",
      "Epoch [5/30], Loss: 1594.4316, Accuracy: 0.5246\n",
      "Epoch [6/30], Loss: 1357.1197, Accuracy: 0.5492\n",
      "Epoch [7/30], Loss: 1408.5149, Accuracy: 0.5208\n",
      "Epoch [8/30], Loss: 1366.9740, Accuracy: 0.5374\n",
      "Epoch [9/30], Loss: 1354.7941, Accuracy: 0.5317\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Güncellenmiş CNN modeli\n",
    "class DisplacementFeatureCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(DisplacementFeatureCNN, self).__init__()\n",
    "        \n",
    "        # Sınıf özelliği olarak num_classes'i sakla\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Özellik çıkarma katmanları\n",
    "        self.features = nn.ModuleList([\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ])\n",
    "        \n",
    "        # MaxPool2d işlemi\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Sınıflandırıcı katmanları\n",
    "        self.classifier = None  # Daha sonra giriş boyutuna göre tanımlanacak\n",
    "    \n",
    "    def forward(self, x):\n",
    "        displacement_features = []\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, nn.Conv2d):\n",
    "                x = layer(x)\n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                x = layer(x)\n",
    "                pooled, indices = F.max_pool2d(x, kernel_size=2, stride=2, return_indices=True)\n",
    "                \n",
    "                # Displacement feature: Havuzlama sonrası max değerlerin konumları\n",
    "                indices_flat = indices.view(indices.size(0), -1).float()\n",
    "                displacement_features.append(indices_flat)  # Düzleştirilmiş displacement feature'lar\n",
    "                \n",
    "                x = pooled\n",
    "\n",
    "        # Düzleştirme\n",
    "        x = torch.flatten(x, 1)\n",
    "        displacement_features = torch.cat(displacement_features, dim=1)\n",
    "        \n",
    "        # Özellik haritası ve displacement birleştirilir\n",
    "        combined_features = torch.cat((x, displacement_features), dim=1)\n",
    "        \n",
    "        # Sınıflandırıcıyı dinamik olarak oluştur\n",
    "        if self.classifier is None:\n",
    "            input_dim = combined_features.size(1)\n",
    "            self.classifier = nn.Sequential(\n",
    "                nn.Linear(input_dim, 256),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=0.3),\n",
    "                nn.Linear(256, self.num_classes)  # num_classes sınıf özelliği olarak kullanılıyor\n",
    "            )\n",
    "            self.classifier = self.classifier.to(combined_features.device)\n",
    "        \n",
    "        # Sınıflandırıcı\n",
    "        x = self.classifier(combined_features)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model tanımlama\n",
    "model = DisplacementFeatureCNN(num_classes=2)  # 2 sınıf\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss fonksiyonu ve optimizer tanımlama\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Model özet bilgisi (isteğe bağlı)\n",
    "print(model)\n",
    "\n",
    "# Eğitim ve test fonksiyonları tanımlandıktan sonra kullanılabilir\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "test_model(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training: 68m 10.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:41:23.765264Z",
     "iopub.status.busy": "2024-12-01T10:41:23.764499Z",
     "iopub.status.idle": "2024-12-01T10:51:09.949987Z",
     "shell.execute_reply": "2024-12-01T10:51:09.948952Z",
     "shell.execute_reply.started": "2024-12-01T10:41:23.765231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=100352, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/20], Loss: 1.2075, Accuracy: 0.4962\n",
      "Epoch [2/20], Loss: 0.6300, Accuracy: 0.6264\n",
      "Epoch [3/20], Loss: 0.5260, Accuracy: 0.7386\n",
      "Epoch [4/20], Loss: 0.4052, Accuracy: 0.8215\n",
      "Epoch [5/20], Loss: 0.3404, Accuracy: 0.8589\n",
      "Epoch [6/20], Loss: 0.2282, Accuracy: 0.9062\n",
      "Epoch [7/20], Loss: 0.1481, Accuracy: 0.9484\n",
      "Epoch [8/20], Loss: 0.0947, Accuracy: 0.9645\n",
      "Epoch [9/20], Loss: 0.0918, Accuracy: 0.9626\n",
      "Epoch [10/20], Loss: 0.0469, Accuracy: 0.9820\n",
      "Epoch [11/20], Loss: 0.0838, Accuracy: 0.9673\n",
      "Epoch [12/20], Loss: 0.0430, Accuracy: 0.9858\n",
      "Epoch [13/20], Loss: 0.0302, Accuracy: 0.9896\n",
      "Epoch [14/20], Loss: 0.0434, Accuracy: 0.9848\n",
      "Epoch [15/20], Loss: 0.0220, Accuracy: 0.9953\n",
      "Epoch [16/20], Loss: 0.0258, Accuracy: 0.9938\n",
      "Epoch [17/20], Loss: 0.0168, Accuracy: 0.9967\n",
      "Epoch [18/20], Loss: 0.0259, Accuracy: 0.9929\n",
      "Epoch [19/20], Loss: 0.0283, Accuracy: 0.9905\n",
      "Epoch [20/20], Loss: 0.0290, Accuracy: 0.9882\n",
      "Epoch [1/20], Loss: 0.0473, Accuracy: 0.9896\n",
      "Epoch [2/20], Loss: 0.0301, Accuracy: 0.9920\n",
      "Epoch [3/20], Loss: 0.0059, Accuracy: 0.9991\n",
      "Epoch [4/20], Loss: 0.0028, Accuracy: 1.0000\n",
      "Epoch [5/20], Loss: 0.0017, Accuracy: 0.9995\n",
      "Epoch [6/20], Loss: 0.0007, Accuracy: 1.0000\n",
      "Epoch [7/20], Loss: 0.0015, Accuracy: 0.9995\n",
      "Epoch [8/20], Loss: 0.0010, Accuracy: 1.0000\n",
      "Epoch [9/20], Loss: 0.0011, Accuracy: 1.0000\n",
      "Epoch [10/20], Loss: 0.0008, Accuracy: 1.0000\n",
      "Epoch [11/20], Loss: 0.0070, Accuracy: 0.9967\n",
      "Epoch [12/20], Loss: 0.0099, Accuracy: 0.9972\n",
      "Epoch [13/20], Loss: 0.0229, Accuracy: 0.9905\n",
      "Epoch [14/20], Loss: 0.0047, Accuracy: 0.9986\n",
      "Epoch [15/20], Loss: 0.0022, Accuracy: 0.9991\n",
      "Epoch [16/20], Loss: 0.0013, Accuracy: 1.0000\n",
      "Epoch [17/20], Loss: 0.0012, Accuracy: 0.9995\n",
      "Epoch [18/20], Loss: 0.0004, Accuracy: 1.0000\n",
      "Epoch [19/20], Loss: 0.0005, Accuracy: 1.0000\n",
      "Epoch [20/20], Loss: 0.0005, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Daha basit bir CNN modeli\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Özellik çıkarma katmanları\n",
    "        self.features = nn.Sequential(\n",
    "            # Blok 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # Daha az filtre\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # Özellik haritası boyutunu azaltır\n",
    "            \n",
    "            # Blok 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Blok 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Sınıflandırıcı katmanları\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 256),  # Daha az nöron\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(256, num_classes)  # Çıkış sınıf sayısı\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # Özellik çıkarımı\n",
    "        x = torch.flatten(x, 1)  # Düzleştirme (flatten)\n",
    "        x = self.classifier(x)  # Sınıflandırıcı\n",
    "        return x\n",
    "\n",
    "# Modeli tanımlama\n",
    "model = SimpleCNN(num_classes=2)  # 2 sınıf (örneğin, imza tanımlama)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss fonksiyonu ve optimizer tanımlama\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Model özet bilgisi (isteğe bağlı)\n",
    "print(model)\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "test_model(model, test_loader, criterion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model başarıyla kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# Modeli dosyaya kaydet\n",
    "torch.save(model.state_dict(), 'signature_model.pth')\n",
    "print(\"Model başarıyla kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T15:53:47.506347Z",
     "iopub.status.busy": "2024-10-29T15:53:47.505410Z",
     "iopub.status.idle": "2024-10-29T15:57:26.689896Z",
     "shell.execute_reply": "2024-10-29T15:57:26.688836Z",
     "shell.execute_reply.started": "2024-10-29T15:53:47.506305Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 203MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0172, Accuracy: 0.9891\n",
      "Epoch [2/5], Loss: 0.0000, Accuracy: 1.0000\n",
      "Epoch [3/5], Loss: 0.0000, Accuracy: 1.0000\n",
      "Epoch [4/5], Loss: 0.0000, Accuracy: 1.0000\n",
      "Epoch [5/5], Loss: 0.0000, Accuracy: 1.0000\n",
      "Test Loss: 0.0000, Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "\n",
    "# Hiperparametreler\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 5\n",
    "test_split_ratio = 0.2\n",
    "\n",
    "# Özel Dataset sınıfı\n",
    "class SignatureDataset(Dataset):\n",
    "    def __init__(self, genuine_dir, forgery_dir, transform=None):\n",
    "        self.genuine_dir = genuine_dir\n",
    "        self.forgery_dir = forgery_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Genuine klasöründen gerçek imzaları ekle\n",
    "        for person_id in os.listdir(genuine_dir):\n",
    "            person_path = os.path.join(genuine_dir, person_id)\n",
    "            if os.path.isdir(person_path):\n",
    "                for img_name in sorted(os.listdir(person_path)):\n",
    "                    img_path = os.path.join(person_path, img_name)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.labels.append(0)  # Gerçek imza için 0\n",
    "\n",
    "        # Forgery klasöründen sahte imzaları ekle\n",
    "        for forgery_type in os.listdir(forgery_dir):\n",
    "            forgery_type_path = os.path.join(forgery_dir, forgery_type)\n",
    "            if os.path.isdir(forgery_type_path):\n",
    "                for person_id in os.listdir(forgery_type_path):\n",
    "                    person_path = os.path.join(forgery_type_path, person_id)\n",
    "                    if os.path.isdir(person_path):\n",
    "                        for img_name in sorted(os.listdir(person_path)):\n",
    "                            img_path = os.path.join(person_path, img_name)\n",
    "                            self.image_paths.append(img_path)\n",
    "                            self.labels.append(1)  # Sahte imza için 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Veri dönüşümleri\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dataset oluşturma\n",
    "full_dataset = SignatureDataset(genuine_dir=\"/kaggle/input/utsignature-verification/UTSig/Genuine\", forgery_dir=\"/kaggle/input/utsignature-verification/UTSig/Forgery/Skilled\", transform=data_transforms)\n",
    "\n",
    "# Eğitim ve test setlerine bölme\n",
    "test_size = int(len(full_dataset) * test_split_ratio)\n",
    "train_size = len(full_dataset) - test_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoader oluşturma\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Modeli yükleme ve ayarlama\n",
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 2)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss ve optimizer tanımlama\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Eğitim fonksiyonu\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Test fonksiyonu\n",
    "def test_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / len(test_loader.dataset)\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Modeli eğit\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "# Modeli test et\n",
    "test_model(model, test_loader, criterion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1352583,
     "sourceId": 2248916,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1512017,
     "sourceId": 2497231,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "3-9-13_NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
